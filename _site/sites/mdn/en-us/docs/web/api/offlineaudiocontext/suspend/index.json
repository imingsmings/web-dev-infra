{"doc":{"isMarkdown":true,"isTranslated":false,"isActive":true,"flaws":{},"title":"OfflineAudioContext: suspend() method","mdn_url":"/en-US/docs/Web/API/OfflineAudioContext/suspend","locale":"en-US","native":"English (US)","browserCompat":["api.OfflineAudioContext.suspend"],"sidebarHTML":"<ol><li><strong><a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a></strong></li><li><strong><a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a></strong></li><li class=\"toggle\"><details open=\"\"><summary>Constructor</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/OfflineAudioContext\"><code>OfflineAudioContext()</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance properties</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/length\"><code>length</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Instance methods</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/resume\"><code>resume()</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/startRendering\"><code>startRendering()</code></a></li><li><em><code>suspend()</code> </em></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Events</summary><ol><li><a href=\"/en-US/docs/Web/API/OfflineAudioContext/complete_event\"><code>complete</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Inheritance:</summary><ol><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/EventTarget\"><code>EventTarget</code></a></li></ol></details></li><li class=\"toggle\"><details open=\"\"><summary>Related pages for Web Audio API</summary><ol><li><a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioBufferSourceNode\"><code>AudioBufferSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioContext\"><code>AudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioDestinationNode\"><code>AudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioNode\"><code>AudioNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioParam\"><code>AudioParam</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioProcessingEvent\"><code>AudioProcessingEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioScheduledSourceNode\"><code>AudioScheduledSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioSinkInfo\"><code>AudioSinkInfo</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorklet\"><code>AudioWorklet</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletGlobalScope\"><code>AudioWorkletGlobalScope</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletNode\"><code>AudioWorkletNode</code></a></li><li><a href=\"/en-US/docs/Web/API/AudioWorkletProcessor\"><code>AudioWorkletProcessor</code></a></li><li><a href=\"/en-US/docs/Web/API/BaseAudioContext\"><code>BaseAudioContext</code></a></li><li><a href=\"/en-US/docs/Web/API/BiquadFilterNode\"><code>BiquadFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConstantSourceNode\"><code>ConstantSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/ConvolverNode\"><code>ConvolverNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DelayNode\"><code>DelayNode</code></a></li><li><a href=\"/en-US/docs/Web/API/DynamicsCompressorNode\"><code>DynamicsCompressorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/GainNode\"><code>GainNode</code></a></li><li><a href=\"/en-US/docs/Web/API/IIRFilterNode\"><code>IIRFilterNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaElementAudioSourceNode\"><code>MediaElementAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioDestinationNode\"><code>MediaStreamAudioDestinationNode</code></a></li><li><a href=\"/en-US/docs/Web/API/MediaStreamAudioSourceNode\"><code>MediaStreamAudioSourceNode</code></a></li><li><a href=\"/en-US/docs/Web/API/OfflineAudioCompletionEvent\"><code>OfflineAudioCompletionEvent</code></a></li><li><a href=\"/en-US/docs/Web/API/OscillatorNode\"><code>OscillatorNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/PeriodicWave\"><code>PeriodicWave</code></a></li><li><a href=\"/en-US/docs/Web/API/StereoPannerNode\"><code>StereoPannerNode</code></a></li><li><a href=\"/en-US/docs/Web/API/WaveShaperNode\"><code>WaveShaperNode</code></a></li></ol></details></li></ol>","sidebarMacro":"APIRef","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<p>\n  The <strong><code>suspend()</code></strong> method of the <a href=\"/en-US/docs/Web/API/OfflineAudioContext\"><code>OfflineAudioContext</code></a> interface schedules a suspension of the time\n  progression in the audio context at the specified time and returns a promise. This is\n  generally useful at the time of manipulating the audio graph synchronously on\n  OfflineAudioContext.\n</p>\n<p>\n  Note that the maximum precision of suspension is the size of the render quantum and the\n  specified suspension time will be rounded down to the nearest render quantum boundary.\n  For this reason, it is not allowed to schedule multiple suspends at the same quantized\n  frame. Also scheduling should be done while the context is not running to ensure the\n  precise suspension.\n</p>"}},{"type":"prose","value":{"id":"syntax","title":"Syntax","isH3":false,"content":"<div class=\"code-example\"><p class=\"example-header\"><span class=\"language-name\">js</span></p><pre class=\"brush: js notranslate\"><code><span class=\"token function\">suspend</span><span class=\"token punctuation\">(</span>suspendTime<span class=\"token punctuation\">)</span>\n</code></pre></div>"}},{"type":"prose","value":{"id":"parameters","title":"Parameters","isH3":true,"content":"<dl>\n  <dt id=\"suspendtime\"><a href=\"#suspendtime\"><code>suspendTime</code></a></dt>\n  <dd>\n    <p>A floating-point number specifying the suspend time, in seconds.</p>\n  </dd>\n</dl>"}},{"type":"prose","value":{"id":"return_value","title":"Return value","isH3":true,"content":"<p>A <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise\"><code>Promise</code></a> resolving to <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/undefined\"><code>undefined</code></a>.</p>"}},{"type":"prose","value":{"id":"exceptions","title":"Exceptions","isH3":true,"content":"<p>The promise is rejected when any exception is encountered.</p>\n<dl>\n  <dt id=\"invalidstateerror\"><a href=\"#invalidstateerror\"><code>InvalidStateError</code></a> <a href=\"/en-US/docs/Web/API/DOMException\"><code>DOMException</code></a></dt>\n  <dd>\n    <p>Returned if the quantized frame number is one of the following:</p>\n    <ul>\n      <li>a negative number</li>\n      <li>less than or equal to the current time</li>\n      <li>greater than or equal to the total render duration</li>\n      <li>scheduled by another suspend for the same time</li>\n    </ul>\n  </dd>\n</dl>"}},{"type":"specifications","value":{"title":"Specifications","id":"specifications","isH3":false,"specifications":[{"bcdSpecificationURL":"https://webaudio.github.io/web-audio-api/#dom-offlineaudiocontext-suspend","title":"Web Audio API"}],"query":"api.OfflineAudioContext.suspend"}},{"type":"browser_compatibility","value":{"title":"Browser compatibility","id":"browser_compatibility","isH3":false,"query":"api.OfflineAudioContext.suspend"}}],"toc":[{"text":"Syntax","id":"syntax"},{"text":"Specifications","id":"specifications"},{"text":"Browser compatibility","id":"browser_compatibility"}],"summary":"The suspend() method of the OfflineAudioContext interface schedules a suspension of the time\n  progression in the audio context at the specified time and returns a promise. This is\n  generally useful at the time of manipulating the audio graph synchronously on\n  OfflineAudioContext.","popularity":0,"modified":"2023-04-08T18:03:46.000Z","source":{"folder":"en-us/web/api/offlineaudiocontext/suspend","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/offlineaudiocontext/suspend/index.md","last_commit_url":"https://github.com/mdn/content/commit/e0177ac1105c77549a7547e47c8cdf9a16bd28d8","filename":"index.md"},"short_title":"suspend()","parents":[{"uri":"/en-US/docs/Web","title":"References"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/OfflineAudioContext","title":"OfflineAudioContext"},{"uri":"/en-US/docs/Web/API/OfflineAudioContext/suspend","title":"suspend()"}],"pageTitle":"OfflineAudioContext: suspend() method - Web APIs | MDN","noIndexing":false}}